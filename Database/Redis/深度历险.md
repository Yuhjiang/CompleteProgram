# Redis

## Redis有几种数据结构
- string: 字符串。`set & get & del & exists`。可以使用`mget & mset`批量读写。使用
`incr & incrby key increment`自增。因为每个字节由8bit构成，可以用作位图bitmap
- list: 列表。插入和删除都是O(1)的复杂度，索引定位速度是O(N)。数据结构是双向快速链表，所以可以
`rpush key valuelist & rpop & lpush & lpop`。可以用`lindex index& lrange start end`取值。
`ltrim start end`保留start～end间的数。在元素较少的情况时，使用一块连续的内存存储，结构是
ziplist，即压缩链表。
- hash: 字典。数组+链表的二维结构。采用的渐进式rehash策略，保留新旧两个hash结构，查询时会
同时查询两个hash结构，然后在后续的定时任务以及hash操作指令中，循序渐进地将旧hash内容一点点
地迁移到新的hash结构中。支持`hset & hgetall & hlen & hget & hmset & hincrby`
- set: 集合。键值对是无序的，当集合最后一个元素被移除后数据结构会被删除，内存回收。
- zset: 有序列表。内部的value都是唯一的，每个value有一个score用于排序，内部实现是一个跳跃链表。
`zadd books 9.0 'think in java'   zadd books 8.0 'java'`, `zrange & zrevrange & 
zcard(count) & zcore & zrank key value & zrangebyscore key start end`

## Redis实现分布式锁
```python
class Lock:
    def __init__(self, timeout=1, sleep=0.1):
        self.timeout = timeout    # 每个协程最多只能持有这么久的时间的锁
        self.sleep = sleep
        self.name = 'MyLock'

    async def __aenter__(self):
        await self.acquire()

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.release()

    async def acquire(self):
        while True:
            if await self.do_acquired():
                print('我获得锁啦')
                return True
            await asyncio.sleep(self.sleep)

    async def release(self):
        redis = await RedisClient.create_redis()
        await redis.delete(self.name)
        print('我释放锁啦')

    async def do_acquired(self):
        """
        判断我们是否真的能获取到锁
        """
        redis = await RedisClient.create_redis()

        my_lock = await redis.set(self.name, 1, expire=self.timeout,
                                  exist='SET_IF_NOT_EXIST')
        return my_lock
```

## 队列阻塞读问题
- 将redis用于异步消息队列的时候，会出现等待pop情况，普通方法是循环里增加sleep，但是太多的线程
sleep会阻塞，拉高redis的QPS。
- 为了避免阻塞，可以使用使用阻塞读`blpop & brpop`。阻塞读在队列没有数据的时候，会立即进入休眠
状态，一旦数据到来，会立即唤醒。
- 但是长时间没有数据，导致连接空闲时，服务器会主动断开连接，`blpop & brpop`会抛出异常，所以
实际使用过程中要做异常处理。

## HyperLogLog用于统计去重
- 一个页面需要记录UV值，每天用户的访问量，需要去重。把所有用户都存入set，然后统计数量非常浪费
空间，不适合，所以要使用HyperLogLog。
- HyperLogLog提供了不精确的去重计数方案，标准误差是0.81%。使用`pfadd &  pfcount` 
- 占据了12KB的内存，存储空间采用了稀疏矩阵存储，当计数变多时，会转成稠密矩阵。

## 布隆过滤器实现去重判断
- 布隆过滤器能准确过滤掉用户已经看过的内容，但是对于用户没看过的新内容，它可能会当成已经看过。
但大部分情况都能准确识别。
- 基本用法`bf.add & bf.exists & bf.madd & bf.mexists`增加（批量）和判断是否存在。
- 使用error_rate, initial_size。error_rate越低，需要的空间越大，initial_size表示预计放入
的元素个数，当实际数量超过这个数值时，误判率会上升。