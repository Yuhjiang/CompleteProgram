# Redis深度历险

## Redis有几种数据结构
- string: 字符串。`set & get & del & exists`。可以使用`mget & mset`批量读写。使用
`incr & incrby key increment`自增。因为每个字节由8bit构成，可以用作位图bitmap
- list: 列表。插入和删除都是O(1)的复杂度，索引定位速度是O(N)。数据结构是双向快速链表，所以可以
`rpush key valuelist & rpop & lpush & lpop`。可以用`lindex index& lrange start end`取值。
`ltrim start end`保留start～end间的数。在元素较少的情况时，使用一块连续的内存存储，结构是
ziplist，即压缩链表。
- hash: 字典。数组+链表的二维结构。采用的渐进式rehash策略，保留新旧两个hash结构，查询时会
同时查询两个hash结构，然后在后续的定时任务以及hash操作指令中，循序渐进地将旧hash内容一点点
地迁移到新的hash结构中。支持`hset & hgetall & hlen & hget & hmset & hincrby`
- set: 集合。键值对是无序的，当集合最后一个元素被移除后数据结构会被删除，内存回收。
- zset: 有序列表。内部的value都是唯一的，每个value有一个score用于排序，内部实现是一个跳跃链表。
`zadd books 9.0 'think in java'   zadd books 8.0 'java'`, `zrange & zrevrange & 
zcard(count) & zcore & zrank key value & zrangebyscore key start end`

## Redis实现分布式锁
- 使用setnx和expire，控制锁的获得和失效。Python里可以同时设置。
```python
class Lock:
    def __init__(self, timeout=1, sleep=0.1):
        self.timeout = timeout    # 每个协程最多只能持有这么久的时间的锁
        self.sleep = sleep
        self.name = 'MyLock'

    async def __aenter__(self):
        await self.acquire()

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.release()

    async def acquire(self):
        while True:
            if await self.do_acquired():
                print('我获得锁啦')
                return True
            await asyncio.sleep(self.sleep)

    async def release(self):
        redis = await RedisClient.create_redis()
        await redis.delete(self.name)
        print('我释放锁啦')

    async def do_acquired(self):
        """
        判断我们是否真的能获取到锁
        """
        redis = await RedisClient.create_redis()

        my_lock = await redis.set(self.name, 1, expire=self.timeout,
                                  exist='SET_IF_NOT_EXIST')
        return my_lock
```

## 队列阻塞读问题
- 将redis用于异步消息队列的时候，会出现等待pop情况，普通方法是循环里增加sleep，但是太多的线程
sleep会阻塞，拉高redis的QPS。
- 为了避免阻塞，可以使用使用阻塞读`blpop & brpop`。阻塞读在队列没有数据的时候，会立即进入休眠
状态，一旦数据到来，会立即唤醒。
- 但是长时间没有数据，导致连接空闲时，服务器会主动断开连接，`blpop & brpop`会抛出异常，所以
实际使用过程中要做异常处理。

## HyperLogLog用于统计去重
- 一个页面需要记录UV值，每天用户的访问量，需要去重。把所有用户都存入set，然后统计数量非常浪费
空间，不适合，所以要使用HyperLogLog。
- HyperLogLog提供了不精确的去重计数方案，标准误差是0.81%。使用`pfadd &  pfcount` 
- 占据了12KB的内存，存储空间采用了稀疏矩阵存储，当计数变多时，会转成稠密矩阵。

## 布隆过滤器实现去重判断
- 布隆过滤器能准确过滤掉用户已经看过的内容，但是对于用户没看过的新内容，它可能会当成已经看过。
但大部分情况都能准确识别。
- 基本用法`bf.add & bf.exists & bf.madd & bf.mexists`增加（批量）和判断是否存在。
- 使用error_rate, initial_size。error_rate越低，需要的空间越大，initial_size表示预计放入
的元素个数，当实际数量超过这个数值时，误判率会上升。
- 传统的set存储整个字符串，而布隆过滤器会存储hash计算后的指纹（一个指纹不足2个字节），能够
节约大量的存储空间。

## GeoHash算法
- GeoHash算法把二维的经纬度数据映射到一维的整数。原理是把地球看成一个二维的平面，划分成多个
正方形并编号，用正方形编号表示位置。然后GeoHash算法会对整数做一次base32编码，存入zset。
zset的value是元素的key，score是GeoHash的52位整数。
- `geoadd zsetName latitude longitude xxx` 存入经纬度名称的三维组。
- `geodist zsetName xxx1 xxx2 unit` 计算两个地方的距离
- `geopos zsetName xx1`获取某个地方的经纬度
- `geohash zsetName xx1` 获取某个地方的hash值
- `georadiusbymember zsetName xx1 距离 单位 count 数量 [desc] withcord withdist withhash`
范围内最多X个单位排序，包含自身，并显示距离，hash值，经纬度

## scan查找键值
- 复杂度O(n)，通过游标分布进行查找，不会阻塞线程。
- 提供limit参数，可以控制每次返回结果的最大条数，limit只是一个hint，实际返回的数据可能
有多有少。
- 提供模式匹配功能
- 服务器不用为游标保存状态，scan会返回客户端游标的数值
- 返回的结果会有重复，需要客户端自己去重
- 返回的结果是空不代表没有数据了，要返回的游标为0说明已经查找完
- `scan 游标 match pattern count limit`
```redis
scan 2 match hello* count 1000
1) "0"
2) 1) "hello4"
   2) "hello3"
   3) "hello2"
   4) "hello1"
```
- zscan遍历zset，sscan遍历set，hscan遍历hash

## Redis单线程性能高的原因
- 采用了非阻塞IO，在读写数据的时候，线程不会阻塞
- Redis会将每个客户端套接字关联一个指令队列，客户端的指令通过队列来排队顺序处理
- Redis也会为每个客户端套接字关联一个响应队列，通过响应队列来将指令的返回结果回复给客户端
- 定时任务使用最小堆，最快要执行的任务放在堆顶，还需要多久的时间记录下来，用于select的timeout参数

## Redis持久化RDB和AOF原理和区别
### RDB（快照）
- RDB会把一次性把数据全量备份，快照是内存数据的二进制序列化形式，存储上十分紧凑
- RDB为了实现一边持久化，一边响应客户端的请求，使用多进程COW（Copy On Write）机制。在持久化
会调用glibc函数fork子进程，子进程刚产生的时候，内存的数据和父进程一样，所以子进程持久化时，不会
修改现有的内存和数据结构，只是对数据结构进行遍历，然后序列化写入磁盘中。
- COW机制是进行数据段页面的分离，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制
一份分离出来，然后对复制出来的页面进行修改，这时子进程的页面是没有变化的。

### AOF
- AOF日志是连续的增量备份，内容是内存数据修改的指令记录文本。AOF在运行过程中会变得无比庞大。
数据库重启时会加载AOF日志进行指令重放。
- Redis会在收到客户端修改指令后，进行参数校验、逻辑处理，没问题的情况下会立即把指令文本存储到
AOF日志中
- Redis使用bgrewriteaof指令，开辟一个子进程对内存遍历，转换成一系列Redis操作指令序列化到一个新的
AOF日志文件。序列化完毕后，将操作期间发生的增加AOF文件追加到新的AOF文件中，追加完毕后用新的
日志文件替换旧的AOF日志文件。
- Redis对日志文件进行写操作时，实际上写到了内核为文件描述符分配的内存缓存中，然后内存会异步
将数据刷回到磁盘。Linux的glibc提供了fsync函数将指定文件的内容强制从内核缓存刷到磁盘，但
因为磁盘IO会影响性能，需要权衡。

## Redis管道
- 管道是客户端提供的功能，和服务端没有关系
- 管道改变了读写顺序，节省IO时间

## Redis的事务
- Redis也有事务，使用 `multi & exec & discard`
- Redis的事务不是真的事务，而是保证事务内的操作能串行执行，即使中间发生了失败，还是会继续执行
- 提供了watch机制，是一种乐观锁。watch在事务开始前，关注多个变量，事务开始后，执行exec时redis
会检查关键变量自watch之后是否有修改，如果关键变量被修改，则exec会返回NULL告知客户端事务
执行失败。
```python
import redis

def key_for(user_id):
    return f'account_{user_id}'

def double_account(client, user_id):
    key = key_for(user_id)
    while True:
        client.watch(key)
        value = int(client.get(key))
        value *= 2
        pipe = client.pipeline(transaction=True)
        pipe.multi()
        pipe.set(key, value)
        try:
            pipe.execute()
            break
        except redis.WatchError:
            continue
    return int(client.get(key))
```

## Redis发布订阅模式
Redis使用PubSub模块，也就是PublisherSubscriber（发布者/订阅者模式）
```python
import redis
import time

client = redis.StrictRedis()
p = client.pubsub()
p.subscribe('codehole')
time.sleep(1)
print(p.get_message())
client.publish('codehole', 'java comes')
time.sleep(1)
print(p.get_message())
client.publish('codehole', 'python comes')
time.sleep(1)
print(p.get_message())
print(p.get_message())

"""
{'type': 'subscribe', 'pattern': None, 'channel': b'codehole', 'data': 1}
{'type': 'message', 'pattern': None, 'channel': b'codehole', 'data': b'java comes'}
{'type': 'message', 'pattern': None, 'channel': b'codehole', 'data': b'python comes'}
None
"""
```

## CAP原理
- C: Consistent 一致性 A: Availability 可用性 P: Partition tolerance 分区容忍性
- 当网路分区发生时，一致性和可用性两难全
- 分布式Redis不满足一致性要求，但保证最终一致性，从节点会追赶主节点的进度，最终保证数据一致性
- Redis同步的是指令流，对自己的状态产生修改性影响的指令记录存入buffer，Redis的buffer是一个
环形数组，所有短时间内无法和从节点同步时，新的指令流会覆盖前面还没有同步的指令
- 快照同步：当当前内存的数据全部快照到磁盘文件中，然后将快照文件的内容全部传送到从节点。从节点
将快照文件接受完毕后，会将当前内存的数据清空然后一次性全量加载快照文件。
- 无盘复制：主节点直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点一边
遍历内存，一边将序列化的内容发送到从节点。

## Redis内存限制
Redis提供`maxmemory`参数来限制内存超出期望大小
- noeviction: 不会继续服务写请求（del请求可以继续服务），读请求可以继续进行
- volatile-lru: 尝试淘汰设置了过期时间的key，最少使用的key优先被淘汰，没有设置过期时间的
key不会被淘汰
- volatile-ttl：比较key的剩余寿命ttl，ttl越小越优先被淘汰
- volatile-random: 过期key集合中随机的key
- allkeys-lru: 淘汰所有的key集合
- allkeys-random: 淘汰随机的key


## Python实现LRU原理
```python
from collections import OrderedDict


class LRUDict(OrderedDict):
    def __init__(self, capacity):
        self.capacity = capacity
        self.items = OrderedDict()

    def __setitem__(self, key, value):
        old_value = self.items.get(key)
        if old_value is not None:
            self.items.pop(key)
            self.items[key] = value
        elif len(self.items) < self.capacity:
            self.items[key] = value
        else:
            self.items.popitem(last=True)
            self.items[key] = value

    def __getitem__(self, key):
        value = self.items.get(key)
        if value is not None:
            self.items.pop(key)
            self.items[key] = value
        return value

    def __repr__(self):
        return repr(self.items)


d = LRUDict(10)
for i in range(10):
    d[i] = i
print(d)
```

## Redis主从同步
### 增量同步
- Redis同步指令流，主节点会把对自己的状态产生修改的指令记录在本地buffer，然后异步将buffer指令
同步到从节点
- 从节点一边执行同步的指令来达到和主节点一样的状态，一边向主节点反馈自己同步的偏移量
- 内存buffer有限的，如果buffer满了，会从头覆盖内容，可能会导致从节点没有跟上主节点进度导致
复制失败，这就回切换到快照同步

### 快照同步
- 在主节点上进行一次bgsave，将内存的数据全部快照到磁盘，然后将快照内容传送到从节点。从节点
接收完毕后，会执行一次全量加载，加载前会将当前内存的数据清空，加载完毕后通知主节点继续进行
增量同步
- 如果快照同步的时间太长或者复制的buffer太小，会导致同步期间的增量指令在复制buffer中被覆盖，
导致快照同步后无法进行增量复制，会陷入快照同步的死循环。

### 增加从节点
- 当从节点刚刚加入集群时，必须先进行一次快照同步，同步完成后再继续进行增量同步

### 无盘复制
- 主节点将直接通过套接字将快照内容发送到从节点。主节点会一边遍历内存，一边将序列化的内容发送到
从节点。

## Redis集群哨兵——sentinel
- 哨兵负责持续监控主从节点的健康，主节点挂掉之后，自动选择一个最优的从节点切换成主节点。
- 客户端连接时，会先连接哨兵，通过哨兵来查询主节点的地址
- 哨兵通过`min-slaves-to-write`&`min-slaves-max-lag`限制主从同步延迟，第一个参数表示
主节点必须至少n个从节点在进行正常复制，否则停止写服务，第二个参数表示在n时间内没有收到从节点
的反馈，意味着从节点同步不正常。

## Steam支持多播的可持久化消息队列
- 数据结构是一个消息链表，每个消息有一个ID和对应的内容
- 每个Stream可以挂多个消费组，每个消费组会有游标在Stream数组上移动，表示当前消费组已经消费
到哪条数据
- 同一个消费组可以挂多个消费者，消费者是竞争关系，任意一个消费者读取了消息都会使游标往前移动
- 消费者内部有一个pending_ids，记录了当前被消费者读取但没有ack的消息
- 如何避免消息丢失？客户端消费者读取了Stream消息后，会存入pending_ids，如果客户端断开了连接，
pending_ids会保存消息ID列表，客户端连上后，可以再次收到pending_ids的ID列表，继续消费

## 过期策略
- Redis会将每个设置了过期时间的key放入独立的字典中，定时遍历字典来删除到期的key。除遍历外，
也会使用惰性策略，即客户端访问这个key的时候，对key的过期时间进行检查，过期了就立即删除。
- 默认每秒10次过期扫描，采用了贪心策略，扫描上线时间默认不超过25ms
    1. 从过期字典中随机选出20个key
    2. 删除20个key中的过期的key
    3. 如果过期的key超过了四分之一，继续重复执行步骤1
- 从节点不会进行过期扫描，主节点的key到期时，会在AOF里增加一条del指令，同步到从节点，从节点
通过执行这条del指令来删除过期的key


## Redis的LRU原理
- Redis使用了近似的LRU算法，每个key增加了一个24bit的字段，标记为上一次访问的时间戳
- Redis执行写操作时，发现内存超过了限制，会执行一次LRU淘汰算法，随机采样5（数量可以设置）个
key，然后淘汰最旧的key，淘汰后内存还是超过限制，就继续随机采样淘汰。

## LFU淘汰算法
- 全称是Least Frequently Used，表示按最近的访问频率进行淘汰。
- 存储了Redis时钟server.lruclock，默认是Unix时间戳对2^24取模，大约97天清零一次，某个key
被访问一次，它的对象头结构lru字段就会被更新为server.lruclock
- lru字段存储了24bit，16bit表示时间戳ldt，8bit存储访问频次的对数值logc，并且会随时间衰减，时间戳
用来存储上一次logc更新的时间

