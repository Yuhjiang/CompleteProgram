# Redis

## Redis有几种数据结构
- string: 字符串。`set & get & del & exists`。可以使用`mget & mset`批量读写。使用
`incr & incrby key increment`自增。因为每个字节由8bit构成，可以用作位图bitmap
- list: 列表。插入和删除都是O(1)的复杂度，索引定位速度是O(N)。数据结构是双向快速链表，所以可以
`rpush key valuelist & rpop & lpush & lpop`。可以用`lindex index& lrange start end`取值。
`ltrim start end`保留start～end间的数。在元素较少的情况时，使用一块连续的内存存储，结构是
ziplist，即压缩链表。
- hash: 字典。数组+链表的二维结构。采用的渐进式rehash策略，保留新旧两个hash结构，查询时会
同时查询两个hash结构，然后在后续的定时任务以及hash操作指令中，循序渐进地将旧hash内容一点点
地迁移到新的hash结构中。支持`hset & hgetall & hlen & hget & hmset & hincrby`
- set: 集合。键值对是无序的，当集合最后一个元素被移除后数据结构会被删除，内存回收。
- zset: 有序列表。内部的value都是唯一的，每个value有一个score用于排序，内部实现是一个跳跃链表。
`zadd books 9.0 'think in java'   zadd books 8.0 'java'`, `zrange & zrevrange & 
zcard(count) & zcore & zrank key value & zrangebyscore key start end`

## Redis实现分布式锁
```python
class Lock:
    def __init__(self, timeout=1, sleep=0.1):
        self.timeout = timeout    # 每个协程最多只能持有这么久的时间的锁
        self.sleep = sleep
        self.name = 'MyLock'

    async def __aenter__(self):
        await self.acquire()

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.release()

    async def acquire(self):
        while True:
            if await self.do_acquired():
                print('我获得锁啦')
                return True
            await asyncio.sleep(self.sleep)

    async def release(self):
        redis = await RedisClient.create_redis()
        await redis.delete(self.name)
        print('我释放锁啦')

    async def do_acquired(self):
        """
        判断我们是否真的能获取到锁
        """
        redis = await RedisClient.create_redis()

        my_lock = await redis.set(self.name, 1, expire=self.timeout,
                                  exist='SET_IF_NOT_EXIST')
        return my_lock
```

## 队列阻塞读问题
- 将redis用于异步消息队列的时候，会出现等待pop情况，普通方法是循环里增加sleep，但是太多的线程
sleep会阻塞，拉高redis的QPS。
- 为了避免阻塞，可以使用使用阻塞读`blpop & brpop`。阻塞读在队列没有数据的时候，会立即进入休眠
状态，一旦数据到来，会立即唤醒。
- 但是长时间没有数据，导致连接空闲时，服务器会主动断开连接，`blpop & brpop`会抛出异常，所以
实际使用过程中要做异常处理。

## HyperLogLog用于统计去重
- 一个页面需要记录UV值，每天用户的访问量，需要去重。把所有用户都存入set，然后统计数量非常浪费
空间，不适合，所以要使用HyperLogLog。
- HyperLogLog提供了不精确的去重计数方案，标准误差是0.81%。使用`pfadd &  pfcount` 
- 占据了12KB的内存，存储空间采用了稀疏矩阵存储，当计数变多时，会转成稠密矩阵。

## 布隆过滤器实现去重判断
- 布隆过滤器能准确过滤掉用户已经看过的内容，但是对于用户没看过的新内容，它可能会当成已经看过。
但大部分情况都能准确识别。
- 基本用法`bf.add & bf.exists & bf.madd & bf.mexists`增加（批量）和判断是否存在。
- 使用error_rate, initial_size。error_rate越低，需要的空间越大，initial_size表示预计放入
的元素个数，当实际数量超过这个数值时，误判率会上升。
- 传统的set存储整个字符串，而布隆过滤器会存储hash计算后的指纹（一个指纹不足2个字节），能够
节约大量的存储空间。

## GeoHash算法
- GeoHash算法把二维的经纬度数据映射到一维的整数。原理是把地球看成一个二维的平面，划分成多个
正方形并编号，用正方形编号表示位置。然后GeoHash算法会对整数做一次base32编码，存入zset。
zset的value是元素的key，score是GeoHash的52位整数。
- `geoadd zsetName latitude longitude xxx` 存入经纬度名称的三维组。
- `geodist zsetName xxx1 xxx2 unit` 计算两个地方的距离
- `geopos zsetName xx1`获取某个地方的经纬度
- `geohash zsetName xx1` 获取某个地方的hash值
- `georadiusbymember zsetName xx1 距离 单位 count 数量 [desc] withcord withdist withhash`
范围内最多X个单位排序，包含自身，并显示距离，hash值，经纬度

## scan查找键值
- 复杂度O(n)，通过游标分布进行查找，不会阻塞线程。
- 提供limit参数，可以控制每次返回结果的最大条数，limit只是一个hint，实际返回的数据可能
有多有少。
- 提供模式匹配功能
- 服务器不用为游标保存状态，scan会返回客户端游标的数值
- 返回的结果会有重复，需要客户端自己去重
- 返回的结果是空不代表没有数据了，要返回的游标为0说明已经查找完
- `scan 游标 match pattern count limit`
```redis
scan 2 match hello* count 1000
1) "0"
2) 1) "hello4"
   2) "hello3"
   3) "hello2"
   4) "hello1"
```
- zscan遍历zset，sscan遍历set，hscan遍历hash

## Redis单线程性能高的原因
- 采用了非阻塞IO，在读写数据的时候，线程不会阻塞
- Redis会将每个客户端套接字关联一个指令队列，客户端的指令通过队列来排队顺序处理
- Redis也会为每个客户端套接字关联一个响应队列，通过响应队列来将指令的返回结果回复给客户端
- 定时任务使用最小堆，最快要执行的任务放在堆顶，还需要多久的时间记录下来，用于select的timeout参数

## Redis持久化RDB和AOF原理和区别
### RDB（快照）
- RDB会把一次性把数据全量备份，快照是内存数据的二进制序列化形式，存储上十分紧凑
- RDB为了实现一边持久化，一边响应客户端的请求，使用多进程COW（Copy On Write）机制。在持久化
会调用glibc函数fork子进程，子进程刚产生的时候，内存的数据和父进程一样，所以子进程持久化时，不会
修改现有的内存和数据结构，只是对数据结构进行遍历，然后序列化写入磁盘中。
- COW机制是进行数据段页面的分离，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制
一份分离出来，然后对复制出来的页面进行修改，这时子进程的页面是没有变化的。

### AOF
- AOF日志是连续的增量备份，内容是内存数据修改的指令记录文本。AOF在运行过程中会变得无比庞大。
数据库重启时会加载AOF日志进行指令重放。
- Redis会在收到客户端修改指令后，进行参数校验、逻辑处理，没问题的情况下会立即把指令文本存储到
AOF日志中
- Redis使用bgrewriteaof指令，开辟一个子进程对内存遍历，转换成一系列Redis操作指令序列化到一个新的
AOF日志文件。序列化完毕后，将操作期间发生的增加AOF文件追加到新的AOF文件中，追加完毕后用新的
日志文件替换旧的AOF日志文件。
- Redis对日志文件进行写操作时，实际上写到了内核为文件描述符分配的内存缓存中，然后内存会异步
将数据刷回到磁盘。Linux的glibc提供了fsync函数将指定文件的内容强制从内核缓存刷到磁盘，但
因为磁盘IO会影响性能，需要权衡。

## Redis管道
- 管道是客户端提供的功能，和服务端没有关系
- 管道改变了读写顺序，节省IO时间

## Redis的事务
- Redis也有事务，使用 `multi & exec & discard`
- Redis的事务不是真的事务，而是保证事务内的操作能串行执行，即使中间发生了失败，还是会继续执行
- 提供了watch机制，是一种乐观锁。watch在事务开始前，关注多个变量，事务开始后，执行exec时redis
会检查关键变量自watch之后是否有修改，如果关键变量被修改，则exec会返回NULL告知客户端事务
执行失败。
```python
import redis

def key_for(user_id):
    return f'account_{user_id}'

def double_account(client, user_id):
    key = key_for(user_id)
    while True:
        client.watch(key)
        value = int(client.get(key))
        value *= 2
        pipe = client.pipeline(transaction=True)
        pipe.multi()
        pipe.set(key, value)
        try:
            pipe.execute()
            break
        except redis.WatchError:
            continue
    return int(client.get(key))
```

## Redis发布订阅模式
Redis使用PubSub模块，也就是PublisherSubscriber（发布者/订阅者模式）
```python
import redis
import time

client = redis.StrictRedis()
p = client.pubsub()
p.subscribe('codehole')
time.sleep(1)
print(p.get_message())
client.publish('codehole', 'java comes')
time.sleep(1)
print(p.get_message())
client.publish('codehole', 'python comes')
time.sleep(1)
print(p.get_message())
print(p.get_message())

"""
{'type': 'subscribe', 'pattern': None, 'channel': b'codehole', 'data': 1}
{'type': 'message', 'pattern': None, 'channel': b'codehole', 'data': b'java comes'}
{'type': 'message', 'pattern': None, 'channel': b'codehole', 'data': b'python comes'}
None
"""
```

## CAP原理
- C: Consistent 一致性 A: Availability 可用性 P: Partition tolerance 分区容忍性
- 当网路分区发生时，一致性和可用性两难全
- 分布式Redis不满足一致性要求，但保证最终一致性，从节点会追赶主节点的进度，最终保证数据一致性
- Redis同步的是指令流，对自己的状态产生修改性影响的指令记录存入buffer，Redis的buffer是一个
环形数组，所有短时间内无法和从节点同步时，新的指令流会覆盖前面还没有同步的指令
- 快照同步：当当前内存的数据全部快照到磁盘文件中，然后将快照文件的内容全部传送到从节点。从节点
将快照文件接受完毕后，会将当前内存的数据清空然后一次性全量加载快照文件。
- 无盘复制：主节点直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点一边
遍历内存，一边将序列化的内容发送到从节点。